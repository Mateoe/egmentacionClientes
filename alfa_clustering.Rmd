---
title: "Prueba clustering"
author: "Equipo TAE"
date: "14/5/2021"
output: html_document
---

```{r, message=FALSE, warning=FALSE}
library(dplyr)
library(knitr)
library(kableExtra)
library(ggplot2)
library(ggcorrplot)
library(factoextra)
options(scipen = 999)
```


# 1. Lectura de la base de datos

```{r}
#Se carga la base de datos
datos_originales <- read.csv("./datos/base_trabajo_segmentacion.csv",
                             sep = ";")

#Se imprime la cabecera

kable(head(datos_originales), "html", align = "c") %>% 
    kable_paper("hover", full_width = F) %>% 
    row_spec(0, background = "tomato", color = "white") %>% 
    scroll_box(width = "100%") %>% 
    kable_styling(bootstrap_options = c("hover", "condensed"))
```

# 2. Limpieza de datos
```{r}
#Se elimina el guión del nit
datos_originales$nit <- gsub("-","", datos_originales$nit)

#Se muestra la cabecera con el cambio realizado
kable(head(datos_originales), "html", align = "c") %>% 
    kable_paper("hover", full_width = F) %>% 
    row_spec(0, background = "tomato", color = "white") %>% 
    scroll_box(width = "100%") %>% 
    kable_styling(bootstrap_options = c("hover", "condensed"))
```


# 3. Normalización de variables
```{r}
#Se crea la función para escalar las variables en el rango 0-1
normalizar <- function(columna){
    normalizada <- (columna-min(columna))/(max(columna)-min(columna))
}

datos_normalizados <- apply(datos_originales[,2:length(datos_originales)], 
                       2,
                       normalizar)

datos_normalizados <- as.data.frame(datos_normalizados)
```

```{r, fig.height = 20, fig.width = 20, fig.align='center'}
corr <-cor(datos_normalizados)
ggcorrplot(corr, lab = T)
```

# 4. Componentes principales

Dividimos el conjunto de datos en:

1. Variables de comportamiento de los clientes en canales y productos.
2. Variables de estados financieros y características de los clientes.

```{r}
#Seleccionamos las variables de comportamiento
comportamiento <- datos_normalizados %>% select(1:30)

#Seleccionamos las variables de estados financieros
estados_f <- datos_normalizados %>% select(31:ncol(datos_normalizados))
```



# 4.1. Para las variables de comportamiento de los clientes en canales y productos

```{r}
cp_comportamiento <- prcomp(comportamiento, scale. = T, center = T)
summary(cp_comportamiento)
```


```{r}
varianza_explicada <- as.data.frame(cp_comportamiento$sdev)
row.names(varianza_explicada) <- colnames(cp_comportamiento$x)
colnames(varianza_explicada) <- "Desviación"
varianza_explicada$Varianza <- varianza_explicada$Desviación^2 
varianza_explicada$Proporción <- varianza_explicada$Varianza/sum(varianza_explicada$Varianza)
varianza_explicada$Acumulada <- cumsum(varianza_explicada$Proporción)
varianza_explicada
```


```{r, fig.height = 7, fig.width = 7, fig.align='center'}
cpx_comportamiento <- cp_comportamiento$x[,1:13]

ggcorrplot(cor(cpx_comportamiento), lab = T)
```


# 4.2. Para las variables de estados financieros y características de los clientes

```{r}
cp_estadosf <- prcomp(estados_f, scale. = T, center = T)
summary(cp_estadosf)
```

```{r}
varianza_explicada <- as.data.frame(cp_estadosf$sdev)
row.names(varianza_explicada) <- colnames(cp_estadosf$x)
colnames(varianza_explicada) <- "Desviación"
varianza_explicada$Varianza <- varianza_explicada$Desviación^2 
varianza_explicada$Proporción <- varianza_explicada$Varianza/sum(varianza_explicada$Varianza)
varianza_explicada$Acumulada <- cumsum(varianza_explicada$Proporción)
varianza_explicada
```

```{r, fig.height = 7, fig.width = 7, fig.align='center'}
cpx_estadosf <- cp_estadosf$x[,1:8]

ggcorrplot(cor(cpx_estadosf), lab = T)
```

# 4.3. Union de los ACP

```{r}
colnames(cpx_comportamiento) <- sapply(colnames(cpx_comportamiento), paste0, arg1 = "_comportamento")
colnames(cpx_estadosf) <- sapply(colnames(cpx_estadosf), paste0, arg1 = "_estadosf")
cpx_datos <- cbind(cpx_comportamiento,cpx_estadosf)
cpx_datos <- as.data.frame(cpx_datos)

```

```{r, fig.height = 20, fig.width = 20, fig.align='center'}
corr <-cor(cpx_datos)
ggcorrplot(corr, lab = T)
```



```{r}
library(ggdendro)
dendrogram <- hclust(dist(cpx_datos, method = 'euclidean'), method = 'ward.D')
ggdendrogram(dendrogram, rotate = FALSE, labels = FALSE, theme_dendro = TRUE) + 
  labs(title = "Dendrograma")
```

```{r}
clases_aj <- cutree(dendrogram, k = 3)
```


```{r}
datos_originales$cluster <- clases_aj

table(datos_originales$cluster)
```

```{r}

resumir_datos <- function(conjunto_datos ,columna){
  
  columna <- enquo(columna)
  
  conjunto_datos %>%
    group_by(cluster) %>% 
    summarise(Media = mean(!!columna),
              Mínimo = min(!!columna),
              Q1 = quantile(!!columna,0.25),
              Mediana = median(!!columna),
              Q3 = quantile(!!columna,0.75),
              Máximo = max(!!columna))
}

resumir_datos(datos_originales, cxc)

```

```{r}
resumir_datos(datos_originales, totalinventory)
```


```{r}
colnames(datos_normalizados)
```

# Pendientes:

1. Aplicar k-means
3. Aplicar algun metodo para la selección optima de clusters
2. Aplicar ambos metodos con todo el conjunto de datos



